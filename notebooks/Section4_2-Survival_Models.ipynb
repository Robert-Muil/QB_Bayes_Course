{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survial Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to event data\n",
    "\n",
    "Often, we are interested in determining how some variable or intervention affects the time to occurence of a certain outcome. For example, a researcher may be interested in how a particular drug affects how long a person will survive with a particular disease. We have already seen how the Bayesian paradigm is able to model binary events. Now, we wish to go a step further and examine the waiting time for the occurence of such events. \n",
    "\n",
    "Recall that the Bayesian paradigm consists of specifying a probability model for the observed data $D$, given an unknown vector of parameters leading to a likelihood function $L(\\theta|D)$. We then assume that the parameters are random and follow some prior distribution $\\pi(\\theta)$. Inference for $\\theta$ is carried out by way of the posterior distribution obtained by Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\pi(\\theta|D)\\propto L(\\theta|D)\\pi(\\theta).\n",
    "$$\n",
    " \n",
    "In survival analysis, the likelihood is somewhat more involved in its formulation. To be able to properly discuss the likelihood specification in survival models, however, we must first discuss several key quantities in survival analysis. As discussed our main outcome of interest is time, which has support $0\\leq t< \\infty$. We denote our time as with a random variable $T$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important quantities in Survival Analysis\n",
    "\n",
    "If the random variable $T$ is the time to the event we are studying, we can make probability statements about the lifetime of individuals. For example, we can calculate the probability of surviving past a particular time $t$ (i.e. $P(T>t)$). This probability, known as the survival function is the primary object of interest in survival analysis. The survival function is denoted by\n",
    "\n",
    "$$S(t) = P(T > t) = 1 - F(t),$$\n",
    "\n",
    "where $F$ is the [CDF](https://en.wikipedia.org/wiki/Cumulative_distribution_function) of $T$.  It is mathematically convenient to express the survival function in terms of the [hazard rate](https://en.wikipedia.org/wiki/Survival_analysis#Hazard_function_and_cumulative_hazard_function), $h(t)$.  The hazard rate is the instantaneous probability that the event occurs at time $t$ given that it has not yet occured.  That is,\n",
    "\n",
    "$$\\begin{align*}\n",
    "h(t)\n",
    "    & = \\lim_{\\Delta t \\to 0} \\frac{P(t < T < t + \\Delta t\\ |\\ T > t)}{\\Delta t} \\\\\n",
    "    & = \\frac{f(t)}{S(t)}\n",
    "\\end{align*}$$\n",
    "\n",
    "Furthermore, we have that\n",
    "\n",
    "$$S(t) = \\exp\\left(-\\int_0^s h(s)\\ ds\\right).$$\n",
    "\n",
    "This representation of the survival function shows that the cumulative hazard function\n",
    "\n",
    "$$H(t) = \\int_0^t h(s)\\ ds$$\n",
    "\n",
    "is an important quantity in survival analysis, since we may consicesly write $S(t) = \\exp(-H(t)).$\n",
    "\n",
    "An important, but subtle, point in survival analysis is [censoring](https://en.wikipedia.org/wiki/Survival_analysis#Censoring). In many survival studies, many data points are `right censored` or rather survival times are usually only known for a portion for those under study where as the remainder are only known to exceed certain values. Specifically, an observation is said to be right censored at $c$ if the exact value of the observation is not known but only that it is greater than or equal to $c$. \n",
    "\n",
    "### Data notation\n",
    "\n",
    "Suppose that there are $n$ subjects under study and that associated with the $i^{th}$ individual is a survival time $t_i*$ and a fixed censoring time $c_i$. The exact survival time $t_i$ will be observed only if $t_i* \\leq c_i$. Hence our data is of the form $(y_i,\\delta_i)$ where\n",
    "$$\n",
    "\\begin{equation}\n",
    "t_i = min(t_i*, c_i)\n",
    "\\end{equation}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\delta_i= I(t_i*\\leq c_i)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In our dataset, $\\delta_i$ is given by `df.event` and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "from pymc3 import Gamma, Poisson, Normal, Model, sample, forestplot, NUTS, Metropolis, find_MAP, starting, traceplot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels import datasets\n",
    "from theano import tensor as tt\n",
    "from io import StringIO\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "SEEDS = 2234323, 172354266\n",
    "np.random.seed(SEEDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mastectomy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use an oncological dataset.\n",
    "In this dataset, each row represents observations from a woman diagnosed with breast cancer that underwent a mastectomy. The column `time` ($t_i$) represents the time (in months) post-surgery that the woman was observed. The column `event` indicates whether or not the woman died during the observation period (i.e. $\\delta_i$). The column `metastized` represents whether the cancer had metastized prior to surgery.\n",
    "\n",
    "We will analyze the relationship between survival time post-mastectomy and whether or not the cancer had metastized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.get_rdataset('mastectomy', 'HSAUR', cache=True).data\n",
    "df.event = df.event.astype(np.int64)\n",
    "df.metastized = (df.metastized == 'yes').astype(np.int64)\n",
    "n_patients = df.shape[0]\n",
    "patients = np.arange(n_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "blue, _, green = sns.color_palette()[:3]\n",
    "\n",
    "ax.hlines(patients[df.metastized.values == 0], 0, df[df.metastized.values == 0].time,\n",
    "          color=blue, label='Not metastized')\n",
    "\n",
    "ax.hlines(patients[df.metastized.values == 1], 0, df[df.metastized.values == 1].time,\n",
    "          color=green, label='Metastized')\n",
    "\n",
    "ax.scatter(df[df.event.values == 1].time, patients[df.event.values == 1],\n",
    "           color='k', zorder=10, label='Death')\n",
    "\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_xlabel('Months since mastectomy')\n",
    "ax.set_yticks([])\n",
    "ax.set_ylabel('Subject')\n",
    "\n",
    "ax.set_ylim(-0.25, n_patients + 0.25)\n",
    "\n",
    "ax.legend(loc='center right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an initial look into survival, we plot the non-parametric Kaplan Meier estimates of the survival via the package `lifelines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "kmf = KaplanMeierFitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "kmf.fit(df.time, event_observed=df.event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df.time\n",
    "event = df.event\n",
    "ix0 = df.metastized==0\n",
    "ix1 = df.metastized==1\n",
    "\n",
    "kmf.fit(time[ix0], event[ix0], label='no Metastasis')\n",
    "ax = kmf.plot(color=green)\n",
    "\n",
    "\n",
    "kmf.fit(time[ix1], event[ix1], label='Metasasis')\n",
    "kmf.plot(ax=ax, ls='dashed', color=blue, figsize=(14,10))\n",
    "ax.set_xlabel('Time (months)')\n",
    "ax.set_ylabel('Survival');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Specification\n",
    "\n",
    "We wish to relate a treatment effect in some way to the time to event outcome. There are several ways to do this, but two main paradigms are pervasive in the literature:\n",
    "\n",
    "1. Proportional Hazards \n",
    "2. Accelerated Failure Time\n",
    "\n",
    "In this lecture we will focus on the first of these models. \n",
    "\n",
    "There are a number of probability models one could use for lifetime data but the Weibull distribution is a very flexible model that is popular with many researchers. Its flexibility comes from the fact that it has a hazard rate which is either monotone increasing, decreasing, or constant. Additionally, it is the only parametric regression model which has both a proportional hazards representation and an accelerated failure-time representation. Again, however, we will only be focusing on the Proportional hazards specification. \n",
    "\n",
    "\n",
    "## Proportional Hazards Model\n",
    "\n",
    "The main objective at this point is to specify a model that relates the group effect to the time outcome. Recall above that the hazard quantifies the instantaneous risk of disease at a given time point. \n",
    "\n",
    "It turns out that the easiest survival parameter to model is the hazard rate: which tells us how quickly individuals of a certain age are experiencing the event of interest. The major approach to modeling the effects of covariates on survival is to model the conditional hazard rate as a function of the covariates. Two general classes of models have been used to relate covariate effects to survival, the family of multiplicative hazard models and the family of additive hazard rate models. We will focus on the former of these here. \n",
    "\n",
    "For the family of multiplicative hazard rate models the conditional hazard rate of an individual with covariate vector $X$ is a product of a baseline hazard rate $h_0(t)$ and a non-negative function of the covariates,\n",
    "$c(\\beta^T X)$, that is, $h (t | z) =h_0(t)c(\\beta^T X)$.\n",
    "   \n",
    "   -$h_0(x)$ may have a specified parametric form or it may be left as an arbitrary nonnegative function.\n",
    "    \n",
    "   - Any nonnegative function can be used for the link function $c()$. Most applications use the Cox (1972) model with $c(\\beta^T X) = \\exp(\\beta^T X)$ which is chosen for its simplicity\n",
    "   - Key Feature: when all the covariates are fixed at time 0, the hazard rates of two individuals with distinct\n",
    "   values of X are proportional. \n",
    "   \n",
    "\n",
    "Using the exponential link, we have\n",
    "$$\n",
    "{\\displaystyle h (t|X_{i})=h _{0}(t)\\exp(\\beta^T X_{i} )}\n",
    "$$\n",
    "\n",
    "That is to say, the model is formulated in such a fashion that the group effect has a multiplicative effect on the hazard. Typically, semi-parametric models which don't have explicit representations of $h_0(t)$ are preferred, however for the purposes of this tutorial, we will assume a particular form for this baseline hazard.\n",
    "\n",
    "The Weibull proportional hazards model models the hazard as \n",
    "\n",
    "$$\n",
    "{\\displaystyle h (t|X_{i})=\\alpha\\lambda t^{\\alpha-1}\\exp(\\beta^TX_{i})}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood Specification\n",
    "\n",
    "Due to right censoring, we need to adjust our likelihood to account for observations where we know that an individual survived up to a particular point. If a person is known to have survived at least to time $t$, then their likelihood contribution is simply the survival function evaluated at the censoring time. We typically express this with an indicator variable $(\\delta_i)$ for each observation denoting whether or not the individual was right censored or observed.\n",
    "\n",
    "First, recall that the Weibull proportional hazards model models the hazard as a function of the covariates. The probability density function is related to the hazard by:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "f(t) = h(t)S(t)\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "The likelihood specification for an individual is therefore given by:\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "L_i &=& [f(t|X)]^{\\delta_i}[S(t|X)]^{1-\\delta_i}\\\\\n",
    "&=& [h(t|X)S(t|X)]^{\\delta_i}[S(t|X)]^{1-\\delta_i}\\\\\n",
    "&=& [\\alpha\\lambda t^{\\alpha-1}\\exp(\\beta^T X)exp(-\\lambda t^{\\alpha}\\exp(\\beta^T X))]^{\\delta_i}[exp(-\\lambda t^{\\alpha}\\exp(\\beta^T X))]^{1-\\delta_i}\\\\\n",
    "&=&[\\alpha\\lambda t^{\\alpha-1}\\exp(\\beta^T X-\\lambda t^{\\alpha}\\exp(\\beta^T X))]^{\\delta_i}[exp(-\\lambda t^{\\alpha}\\exp(\\beta^T X))]^{1-\\delta_i}\\\\\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specification in PyMC3\n",
    "\n",
    "We've formulated the mathematical form of our likelihood - we now need to implement it. PyMC3 makes this really easy to do with the `DenistyDist` class. All that is needed to specify a likelihood is a python function that passes the log of the likelihood.\n",
    "\n",
    "Continuing from before:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "log L_i &=& \\log[[\\alpha\\lambda t^{\\alpha-1}\\exp(\\beta^T X-\\lambda t^{\\alpha}\\exp(\\beta^T X))]^{\\delta_i}[exp(-\\lambda t^{\\alpha}\\exp(\\beta^T X))]^{1-\\delta_i}]\\\\\n",
    "&=& \\delta_i \\log[\\alpha\\lambda t^{\\alpha-1}\\exp(\\beta^T X-\\lambda t^{\\alpha}\\exp(\\beta^T X))]+(1-\\delta_i)(-\\lambda t^{\\alpha}\\exp(\\beta^T X))\\\\\n",
    "&=&\\delta_i(\\log\\alpha+\\log\\lambda+(\\alpha-1)\\log t + \\beta^T X) - \\lambda t^{\\alpha}\\exp(\\beta^T X)\n",
    "\\end{eqnarray}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemented in PyMC3, this is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "```python\n",
    "def logp(event):\n",
    "    return (event*(tt.log(α) + tt.log(λ) \n",
    "                   + tt.log(tt.exp(β*np.array(metast)))\n",
    "                   + (α-1)*tt.log(np.array(time))) \n",
    "            - (λ*tt.exp(β*np.array(metast)) \n",
    "                   * np.array(time)**α))\n",
    "    \n",
    "survival = pm.DensityDist('survival', logp, observed={'event':event})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Distribution specification:\n",
    "Recall that in a Bayesian framework, estimated parameters are considered random variables - so we need to place a prior distribution on them. Looking at the parameters to estimate, we have \n",
    "\n",
    "1. Weibull baseline hazard parameters: $\\alpha$,$\\lambda>0$\n",
    "    - A natural prior for these parameters would be the Gamma distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pymc3 import Gamma\n",
    "\n",
    "params = (5, 1), (1, 3), (5, 5), (0.5, 0.5), (10, 1)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(params), figsize=(14, 4), sharey=True)\n",
    "for ax, (alpha, beta) in zip(axes, params):\n",
    "    sns.distplot(Gamma.dist(alpha, beta).random(size=1000), ax=ax, kde=False)\n",
    "    ax.set_xlim(0, 20)\n",
    "    ax.set_title(r'$\\alpha={0}, \\beta={1}$'.format(alpha, beta));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Alternatively, one might specify a Half Cauchy distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(pm.HalfCauchy.dist(1).random(size=1000), kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Group effect: $-\\infty<\\beta<\\infty$\n",
    "\n",
    "For the effect of metastasis, the most natural prior is the Normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(pm.Normal.dist(0,100).random(size=3000), kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation in PyMC3\n",
    "\n",
    "Putting all the pieces together, we can fit the model using the pymc framework as so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metast = df.metastized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "n_tune = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with Model() as weibull_model:\n",
    "    \n",
    "    # Weibull shape parameter\n",
    "    α = pm.HalfCauchy(\"α\", 1)\n",
    "    \n",
    "    # Effects of metastisis\n",
    "    λ = pm.HalfCauchy(\"λ\", 1)\n",
    "    \n",
    "    # Weibull scales\n",
    "    β = pm.Normal('β', 0, 100)\n",
    "    \n",
    "    linear = tt.exp(β*metast)\n",
    "\n",
    "    # Weibull survival likelihood, accounting for censoring\n",
    "    def logp(event):\n",
    "        return event*(tt.log(α) + tt.log(λ) + tt.log(linear) \n",
    "                      + (α-1)*tt.log(np.array(time))) - (λ*linear * np.array(time)**α)\n",
    "    \n",
    "    survival = pm.DensityDist('survival', logp, observed={'event':event})\n",
    "    \n",
    "    weibull_trace = pm.sample(n_iterations, tune=n_tune, cores=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the posterior samples and assess convergence of the Markov Chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "az.plot_trace(weibull_trace, var_names=['α', 'λ', 'β']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have fit a proportional hazards model, the interpretation of the group effect is straightforward (at least with respect to the hazard). We need only to exponentiate the $\\beta$ posterior samples for the effect size and corresponding credible intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hr_samps = np.exp(weibull_trace['β'])\n",
    "print('Hazard ratio (metastisized vs not metastisized) at 5 years: {0:.2f} {1}'.format(hr_samps.mean(), \n",
    "                                                            np.percentile(hr_samps, [2.5, 97.5]).round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interpretation: This means that the hazard for the group with metastasis is bigger\n",
    "than the one for the group with no metastasis. This indicates metastasis has a negative effect on survival. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Survival quantites\n",
    "\n",
    "Given that we have posterior samples for each of the parameters, it is straightforward to obtain posterior survival curves, hazard rates, etc, with corresponding credible intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Plot survival curves \n",
    "n_intervals = 120\n",
    "interval_bounds = np.arange(0, n_intervals + 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#baseline_lam = np.exp(weibull_trace['β'][n_burn:,0])\n",
    "baseline_lam = np.repeat(1., n_iterations*2)\n",
    "metast_lam = np.exp(weibull_trace['β'])\n",
    "λ_trace = weibull_trace['λ']\n",
    "α_trace = weibull_trace['α']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_with_hpd(x, lam, f, ax, linestyle='-', color=None, label=None, alpha=0.05, debug=False, **kwargs):\n",
    "\n",
    "    m = np.median(f(lam, **kwargs), axis=0)\n",
    "    \n",
    "    percentiles = 100 * np.array([alpha / 2., 1. - alpha / 2.])\n",
    "    hpd = np.percentile(f(lam, **kwargs), percentiles, axis=0)\n",
    "    \n",
    "    if debug:\n",
    "        import pdb;pdb.set_trace()\n",
    "    ax.fill_between(x, hpd[0], hpd[1], color=color, alpha=0.15)\n",
    "    ax.step(x, m, color=color, linestyle=linestyle, label=label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def cum_weibull_hazard(lam, α=α_trace ,λ=λ_trace, t=n_intervals):\n",
    "    return (λ_trace.reshape(-1,1)*lam.reshape(-1,1) * np.arange(t)) ** α.reshape(-1,1)\n",
    "\n",
    "def weibull_survival(lam,α=α_trace, λ=λ_trace, t=n_intervals):\n",
    "    return np.exp(-cum_weibull_hazard(lam, α, λ, t))\n",
    "\n",
    "def cum_hazard(hazard, n=n_intervals):\n",
    "    return (np.arange(n) * hazard.reshape(-1,1)).cumsum(axis=-1)\n",
    "\n",
    "def survival(hazard):\n",
    "    return np.exp(-cum_hazard(hazard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (hazard_ax, surv_ax) = plt.subplots(ncols=2, sharex=True, sharey=False, figsize=(16, 6))\n",
    "\n",
    "plot_with_hpd(interval_bounds[:-1], baseline_lam, cum_weibull_hazard,\n",
    "              hazard_ax, color=green, linestyle=':', label='No Metastasis')\n",
    "plot_with_hpd(interval_bounds[:-1], metast_lam, cum_weibull_hazard,\n",
    "              hazard_ax, color=blue, linestyle='--', label='Metastisized')\n",
    "\n",
    "hazard_ax.set_xlim(0, n_intervals);\n",
    "hazard_ax.set_xlabel('Followup time');\n",
    "\n",
    "hazard_ax.set_ylabel(r'Cumulative hazard $\\Lambda(t)$');\n",
    "\n",
    "hazard_ax.legend(loc=2);\n",
    "\n",
    "plot_with_hpd(interval_bounds[:-1], baseline_lam, weibull_survival,\n",
    "              surv_ax, color=green, linestyle=':')\n",
    "plot_with_hpd(interval_bounds[:-1], metast_lam, weibull_survival,\n",
    "              surv_ax, color=blue, linestyle='--')\n",
    "\n",
    "\n",
    "surv_ax.set_xlim(0, n_intervals);\n",
    "surv_ax.set_xlabel('Followup time');\n",
    "\n",
    "surv_ax.set_ylabel('Survival function $S(t)$');\n",
    "\n",
    "fig.suptitle('Bayesian survival model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our KM estimate from earlier, we see that the posterior survival curves follow closely to the non-parametric K-M estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## Hazard ratio comparing 2 groups at a given time point \n",
    "def weibull_hazard(lam, t,α=α_trace, λ=λ_trace):\n",
    "    return (α.reshape(-1,1) * λ.reshape(-1,1) * lam.reshape(-1,1) * t**(α.reshape(-1,1) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course, obtain our hazard ratio from the posterior samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hazard_ratio = weibull_hazard(metast_lam, 60)/weibull_hazard(baseline_lam, 60)\n",
    "print('Hazard ratio (metastisized vs notmetastisized) at 5 years: {0} {1}'.format(hazard_ratio.mean(), \n",
    "                                                                     np.percentile(hazard_ratio, [2.5, 97.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Other quantities of interest:\n",
    "\n",
    "baseline_survival = weibull_survival(baseline_lam)\n",
    "metast_survival = weibull_survival(metast_lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Time where surivial is .5\n",
    "np.where(baseline_survival.mean(axis=0)<=0.5)[0][0]\n",
    "np.where(metast_survival.mean(axis=0)<=0.5)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "baseline_survival_5 = baseline_survival[:, 60]\n",
    "metast_survival_5 = metast_survival[:, 60]\n",
    "print('Baseline 5-year median survival: {0:.2f} {1}'.format(np.median(baseline_survival), \n",
    "                                                        np.percentile(baseline_survival, [2.5, 97.5]).round(2)))\n",
    "\n",
    "print('Metastasis group median 5-year survival: {0:.2f} {1}'.format(np.median(metast_survival_5), \n",
    "                                                        np.percentile(metast_survival_5, [2.5, 97.5]).round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Heart transplant survival\n",
    "\n",
    "Try your hand at building a survival model using PyMC3. Here is a small dataset based on 69 patients receiving heart transplants. Taken from \"The Statistical Analysis of Failure Time Data\" by Kalbfleisch and Prentice, Appendix I, pages 230-232 from stalib data depository. http://lib.stat.cmu.edu/datasets/stanford \n",
    "  \n",
    "Data columns:\n",
    "- Age at transplant in years \n",
    "- Survival Status 1=dead 0=alive \n",
    "- Survival Time after transplant in days \n",
    "\n",
    "Estimate the relationship between age at transplant and survival probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_str = \"\"\"\n",
    "41 1 5 \n",
    "40 1 16 \n",
    "54 1 16 \n",
    "29 1 17 \n",
    "55 1 28 \n",
    "52 1 30 \n",
    "40 1 39 \n",
    "35 0 39 \n",
    "56 1 43 \n",
    "36 1 45 \n",
    "42 1 51 \n",
    "50 1 53 \n",
    "42 1 58 \n",
    "52 1 61 \n",
    "61 1 66 \n",
    "45 1 68 \n",
    "49 1 68 \n",
    "53 1 72 \n",
    "47 1 72 \n",
    "64 1 77 \n",
    "51 1 78 \n",
    "53 1 80 \n",
    "54 1 81 \n",
    "56 1 90 \n",
    "53 1 96 \n",
    "48 1 100 \n",
    "28 0 109 \n",
    "46 1 110 \n",
    "23 0 131 \n",
    "47 1 153 \n",
    "43 1 165 \n",
    "26 0 180 \n",
    "52 1 186 \n",
    "47 1 188 \n",
    "51 1 207 \n",
    "51 1 219 \n",
    "47 0 265 \n",
    "48 1 285 \n",
    "19 1 285 \n",
    "49 1 308 \n",
    "42 1 334 \n",
    "44 0 340 \n",
    "47 1 342 \n",
    "54 0 370 \n",
    "48 0 397 \n",
    "52 0 445 \n",
    "46 0 482 \n",
    "48 0 515 \n",
    "52 0 545 \n",
    "48 1 583 \n",
    "26 0 596 \n",
    "47 0 630 \n",
    "47 0 670 \n",
    "50 1 675 \n",
    "58 1 733 \n",
    "32 0 841 \n",
    "44 1 852 \n",
    "41 0 915 \n",
    "38 0 941 \n",
    "45 1 979 \n",
    "48 1 995 \n",
    "43 1 1032 \n",
    "36 0 1141 \n",
    "45 0 1321 \n",
    "53 1 1386 \n",
    "48 0 1407 \n",
    "40 0 1571 \n",
    "48 0 1586 \n",
    "33 0 1799 \n",
    "\"\"\"\n",
    "\n",
    "transplant_data = pd.read_table(StringIO(data_str), sep='\\s+', names=['transplant_age', 'death', 'time'])\n",
    "transplant_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# References \n",
    "\n",
    "Ibrahim, Joseph G., Ming‐Hui Chen, and Debajyoti Sinha. Bayesian survival analysis. John Wiley & Sons, Ltd, 2005.\n",
    "\n",
    "Klein, John P., Moeschberger, Melvin L. Survival Analysis: Techniques for Censored and Truncated Data Second Edition. Springer, 2003.\n",
    "\n",
    "[Survival Distributions, Hazard Functions, Cumulative Hazards](https://web.stanford.edu/~lutian/coursepdf/unit1.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
